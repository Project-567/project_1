{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridworld with Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value Iteration\n",
    "import numpy as np\n",
    "from random import randint\n",
    "\n",
    "# display output\n",
    "from random import uniform\n",
    "import time\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [[-1, 0], [0, 1], [1, 0], [0, -1]] #up, right, down, left = (clockwise from up) \n",
    "action_count = len(actions) # total number of actions\n",
    "gridSize = 5 # create a square grid of gridSize by gridSize\n",
    "state_count = gridSize*gridSize # total number of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.25, 0.25, 0.25])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize a policy: create an array of dimension (number of states by number of actions)\n",
    "# for equal probability amongst all actions, divide everything by the number of actions\n",
    "policy = np.ones([state_count, action_count]) / action_count\n",
    "\n",
    "# policy at state 0 = [0, 0]\n",
    "# returns a probability for each action given state\n",
    "policy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gridworld():\n",
    "    def __init__(self, gridSize):\n",
    "        self.valueMap = np.zeros((gridSize, gridSize))\n",
    "        self.states = [[i, j] for i in range(gridSize) for j in range(gridSize)]\n",
    "        self.size = gridSize\n",
    "        self.new_pos = [0, 0] # initialize new position for p_transition\n",
    "        self.pos_check = [0, 0] # a copy of new position\n",
    "        self.transition_prob = 1 # deterministic\n",
    "    \n",
    "    def initial_state(self):\n",
    "        # randomly generate an initial state\n",
    "        i = random.randint(0, len(self.states)-1)\n",
    "        rand_state = self.states[i]\n",
    "        return rand_state\n",
    "    \n",
    "    def possible_states(self):\n",
    "        # return the possible states\n",
    "        return self.states\n",
    "    \n",
    "    def reward(self, current_pos, action):\n",
    "        # return the reward        \n",
    "        \n",
    "        # take action in current pos\n",
    "        self.new_pos = np.array(current_pos) + np.array(action)\n",
    "\n",
    "        # normally, reward = 0\n",
    "        reward = 0\n",
    "\n",
    "        # if new pos results in off the grid, return reward -1\n",
    "        if -1 in self.new_pos or self.size in self.new_pos:\n",
    "            reward = -1\n",
    "        # if in state A, transition to state A'\n",
    "        if current_pos == [0, 1]:\n",
    "            reward = 10\n",
    "        # if in state B, transition to state B'\n",
    "        if current_pos == [0, 3]:\n",
    "            reward = 5\n",
    "        return reward\n",
    "    \n",
    "    # def transition_probability(self, current_pos, new_pos):\n",
    "        # a function that returns the entries of the transition probability matrix?\n",
    "        # eg. input current state, new state, output = 0.25...0.5...1 ... etc. ?\n",
    "    \n",
    "    def p_transition(self, current_pos, action):\n",
    "        # return the transition probability\n",
    "        # get next position: state: [0, 0], action: [0, 1], new_state = [0, 1]\n",
    "        self.new_pos = np.array(current_pos) + np.array(action)\n",
    "        self.pos_check = self.new_pos # make a copy of new pos before being overwritten below\n",
    "\n",
    "        # if taking an action crosses the border = agent stays in same position\n",
    "        if -1 in self.new_pos or self.size in self.new_pos: \n",
    "            self.new_pos = current_pos\n",
    "            \n",
    "        # if in state A, transition to state A'\n",
    "        if current_pos == [0, 1]:\n",
    "            self.new_pos = [4, 1]\n",
    "            \n",
    "        # if in state B, transition to state B'\n",
    "        if current_pos == [0, 3]:\n",
    "            self.new_pos = [2, 3]\n",
    "        return self.new_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Value Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a grid object\n",
    "grid = Gridworld(5)\n",
    "grid.valueMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate action value with the current policy\n",
    "def calculate_action_value(state, value):\n",
    "    A = np.zeros(action_count)\n",
    "    \n",
    "    # perform 4 actions per state and add the rewards (value)\n",
    "    for action_number, action in enumerate(actions):\n",
    "            \n",
    "        # get next position and reward\n",
    "        new_position = grid.p_transition(state, action)\n",
    "        reward = grid.reward(state, action)\n",
    "        \n",
    "        # get next position and reward\n",
    "        new_position = grid.p_transition(state, action)\n",
    "        reward = grid.reward(state, action)\n",
    "\n",
    "        # calculate value of action: transition_prob*[r + gamma * value(s')]\n",
    "        A[action_number] += grid.transition_prob*(reward+(discount_factor*value[new_position[0], new_position[1]]))\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random policy\n",
    "random_policy = np.random.randint(1000, size=(state_count, action_count))\n",
    "random_policy = random_policy/random_policy.sum(axis=1)[:,None]\n",
    "policy = random_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'delta: 9.973604164770222e-07 iterations: 1605'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Value Iteration\n",
    "\n",
    "discount_factor = 0.99 # small prefer immediate reward, large prefer future reward\n",
    "iterations = 0\n",
    "theta = 0.000001\n",
    "delta_list = []\n",
    "\n",
    "while True:\n",
    "    delta = 0\n",
    "    iterations+=1\n",
    "    valueMap_copy = np.copy(grid.valueMap)\n",
    "\n",
    "    \n",
    "    # FIND OPTIMAL VALUE #######################################################   \n",
    "    # start with the first state in the state list\n",
    "    for state_number, state in enumerate(grid.states):\n",
    "        value = 0\n",
    "\n",
    "        # calculate best action value given current state and value function\n",
    "        action_values = calculate_action_value(state, grid.valueMap)\n",
    "\n",
    "        # choose the best action value\n",
    "        best_action_value = np.max(action_values)\n",
    "\n",
    "        # value of current state is equal to the best action value\n",
    "        value = best_action_value\n",
    "\n",
    "        # replace the value in valueMap with the value\n",
    "        valueMap_copy[state[0], state[1]] = value\n",
    "\n",
    "        # calculate delta\n",
    "        delta = max(delta, np.abs(value - grid.valueMap[state[0], state[1]]))       \n",
    "        clear_output(wait=True)\n",
    "        display('delta: ' + str(delta) + ' iterations: ' + str(iterations))\n",
    "\n",
    "    # save data for plot\n",
    "    delta_list.append(delta)\n",
    "\n",
    "    # overwrite the original value map (after complete iteration of every step)\n",
    "    grid.valueMap = valueMap_copy\n",
    "\n",
    "    # stop when change in value function falls below a given threshold\n",
    "    if delta < theta:\n",
    "        break\n",
    "\n",
    "# EXTRACT POLICY FROM OPTIMAL VALUE #####################################################\n",
    "for state_number, state in enumerate(grid.states):\n",
    "    # using the current value map (optimal at this point), calculate the action values\n",
    "    action_values = calculate_action_value(state, grid.valueMap)\n",
    "    # return the action with the highest action value\n",
    "    best_action = np.argmax(action_values)\n",
    "    # update policy accordingly\n",
    "    policy[state_number] = np.eye(action_count)[best_action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[201.9998, 204.0402, 201.9998, 199.0402, 197.0498],\n",
       "       [199.9798, 201.9998, 199.9798, 197.98  , 196.0002],\n",
       "       [197.98  , 199.9798, 197.98  , 196.0002, 194.0402],\n",
       "       [196.0002, 197.98  , 196.0002, 194.0402, 192.0998],\n",
       "       [194.0402, 196.0002, 194.0402, 192.0998, 190.1788]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print value map to 4 decimal places\n",
    "np.set_printoptions(precision=4)\n",
    "grid.valueMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcHHWd//HXp+e+Z5JMJncmCTfREEg4RO5TRPBc8VhAUdYbddVFXdddd93FY1dEXTUrKCjigcglPxDBIB4EEo5whJAECLkzIZncxxyf3x/f74TOMDOZq7smU+/nI52urqqu76drqvtT329VfcvcHRERSa9M0gGIiEiylAhERFJOiUBEJOWUCEREUk6JQEQk5ZQIRERSTolgCDKzRjNzMytMOpZcMLNtZjZ1qJZvZi+a2ZmDWN6kWGbBYC1TZDApEeSAmd1tZl/pYvyFZrY2yR/47B85M7vUzP6c4/LmmtkHsse5e6W7P5/LcnuSXb6Z/cTM/qO/y4rrsC3+0G8zsxfM7MdmdkhWeS/FMtsGI/7B1JttIP4Nd2V9xm1mdsIAyiyMOzqN/V1GN8s92sweNbMdZvaImb22h3mPjJ9rs5ktMbMLOk2/3MyWxc96l5mNHcxYhxolgty4HnivmVmn8X8P3OjurQnENOiGa42lH/7m7pVADXAmsBNYYGbTkw1rUH0sJrOOx9+SCqSr7c7MSoDbgB8DdcBNwK1mVtTFvMXA7cBvgRHAR4CbzGxanH4G8BXgfGAksBL4WU4+zFDh7noM8gMoAzYDJ2eNqwN2ATPi6zcCjwFbgBXAv2bN2wg4UBhfvwicmTX9X4GfZb0+Hvgr0Aw8AZzaQ2wvEn6sDo/xtAHbgOY4vQT4JvASsA74AVAWp51K+FL8E7AW+Gn8XHcCTcCmODwhzv/VuPxdsYzvxvEOHBSHa4Ab4vuXA/8MZOK0S4E/x3g2AS8Ab+jmc70PuCPr9RLg11mvVwBHZZcPXA60AHtifHdkraPPAAvj3/GXQGk35V4K/LmL8XcCN3fz97wUeB7YGj/Te7Le90FgUZz2DHB0HH84MDf+jZ8GLsh6z1zgA93FFMv+UFwnzcD3AOtuG+jis+yz/E7Tvhu3iS3AI8DrsqYVAl8ClsXp84FxhG3Vge2x3LfF+T8ELAVeBm4FxmYtxwk/2EuBpV3EcR6wPOu1AavI+t5kTTsqrgfLGnc/8OU4fDXw7axpk2L5k5P+bcnVQzWCHHD3ncCvgIuzRv8d8Ky7PxFfb4/TawlJ4cNm9ua+lmVm44HfAf9B2Lv5DPAbM6vfT4yLCF+8v3nYw6uNk64CDiF8WQ4CxgP/kvXWMbGcyYQf0gxhL2wy4Quzk/DjgLt/EXiQV/YmP9ZFKN8hJIOpwCmEdfK+rOnHAYuBUcDXgWu7qGkBPACcZGYZMxsHFAMnxHU0Fagk/LBnr4M5wI3A12N8b8qa/HfAucAU4LWEH9e+uAU4qfNIM6sAriEktCrgdcDjcdo7CEn+YqAauAB4Oe7V3gH8HhgNfBy40cwO7UM85wOz42f5O+CcHraBvpgXlzkCuBn4ddw7B/gs8HbCeqwFPkBIPCfH6UfGcn9jZmcT9sLfTtjmVhP+NtkuiJ/hNV3EcSRZf18Pv+BPxvFd6bwNGTC9m+kdw8OphrcPJYLcuR54u5mVxtcXx3EAuPtcd3/S3dvdfSGhKntKP8p5L3CXu98Vl3UvYc/rvL4uKP7AXg58yt03uvtW4D+Bi7JmayfsOe12953u/rK7/8bdd8T5v9rbzxEPnl4EfN7dt7r7i8B/E5rQOix39//z0L5+PTAWaOi8LA9t/lsJCexk4B5gtZkdFuN50N3be782uMbdV7v7RsKP8FF9eC+EH7IR3UxrB6abWZm7r3H3p+P4DxCS0iMeLHX35YQaXyVwlbvvcff7CTWOd/UhnqvcvdndXwL+2I/Pc42ZNcfHox0j3f2ncVtpJSTqasIORMfn+YK7L4nb5uNxfXblPcCP4jy7gCuBU8xsQtY8/+num+KOVmeVhNpbts1AVRfzPkOoEXzKzIrM7Fzg9UB5nH43cJGZTTezMsKOkGdNH3aUCHLE3f8MbADeHNsejwV+3jHdzI4zsz+aWZOZbSbsmY3qR1GTgXdkfUmbCRt1fw5u1RM29gVZy7o7ju/QFL+oHZ+j3Mx+aGbLzWwL8CegtpdnyIwCighNQh2WE/YIO6ztGHD3HXGwspvlPUBovjo5Ds8lJIFT4uu+WJs1vKOHMrszHnjVj567bwfeSfh7rzGz38VkBTCR0IzS2ThgRadE1nk97c9AP88n3L02Po7uGGlmnzOzZ+M2vAmo4JXtuLvP05VxZG0H7r4lLi/7M67o4f3bCEkoWzVh52Af7r4HuBB4M2G9XEGozayM0+8m1LBvJTQTLibUdFf28rMccJQIcusGQk3gvcA97r4ua9rPCQesJrp7DaEtvqsmDwjNSNl7I2OyhlcAP836kta6e4W7X9WL+Dp3PbuBsMEfmbWsGg8HQrt7zz8ChwLHuXs1r1T7rZv5O5fXQkhmHSYR2nb7oyMRnBSHH2D/iSBX3e++hdAs9uoC3e9x97MIyfpZ4P/ipBXAtC7eshqYaGbZ39fs9dTT9rE//f78ZnYa8GngbYSmnzrCD3LH3767z9NVmavJ2g7MrCouL3tb6CnWp4EZWe83QhPS013NHGseJ7v7SHd/Q4zz4azp17j7Qe7eQKh9tRNqEsOSEkFu3UA4MPtBspqFoipgo7vvMrNjgXf3sJzHCVXVIjObRWhH7fAz4E1mdo6ZFZhZqZmd2qlK3Z11wIR4FgVxj/P/gG+Z2WgIxyDM7JwellFFSB7NZjYC+HIXZXR5zn5s7vkV8FUzqzKzyYQflv6eofEAcBrh4PZKwg/xuYQzPx7r5j3dxtdXcf1PMbPvEBLSv3UxT0M8jbgC2E344ezY0/8R8BkzO8aCg+I6mUfYi/9c3AZOBd4E/CK+73HgrbF2dhBwWR/C3mcb6KMqoJWQ0IsIxzcqsqb/CPgPM5sWP89RZjYi/t1fZt/1fhNwmZm9Nh5j+C9Cc15v98LvBwrM7KPx/VcQdjK63AGI5ZTGdXYloRnvhjitLJ5eanH9/xD4lrt3bnoaNpQIcii2ef+V8OW4vdPkjwBfMbOthDbIX/WwqC8R9lg2EX5c9jYxufsKQjX3C4Qzb1YQDtL15m97P2GPaa2ZbYjj/olwZsZDsannD4Q9/u5cTThLagPwEKEpKdu3CcdKNpnZNV28/+OEPdrnCWcI/Ry4rhexv4q7P0f4YX0wvt4Sl/sX7/4c/muBI2JT2K39KRc4wcy2Ec6MmUtokpjt7k92MW+GkOxWE5qOTgE+HOP9NeEYy88JTRq3AiNiU8abgDcQ1vP/Ahe7+7Nxmd8inPm0jrDD0fkga0+62gZ66y7C9rGE0ISyBViTNf0b8TPcF6fNATqOmX0Z+Hlc72+NzTFfIZzSuYZQ43lPbwOJzZUXEo5LNBNq4Re6ewuAmX3JzO7IesulsZz1hBrk2R3zErbnXxC2pYcIyeRVSX04sXBwXURE0ko1AhGRlFMiEBFJOSUCEZGUUyIQEUm5A6LTsFGjRnljY2PSYYiIHFAWLFiwwd177G4GDpBE0NjYyPz585MOQ0TkgGJmy/c/l5qGRERST4lARCTllAhERFJOiUBEJOWUCEREUi5nicDMrjOz9Wb2VNa4EWZ2r4WbRd9rZnW5Kl9ERHonlzWCnxC6AM52JXCfux9M6JHwyhyWLyIivZCzRODuf+LVd2i6kFf65b+ecIegnLn1sVX87KFenUYrIpJa+T5G0ODuHf2Vr6WLe892MLPLzWy+mc1vamrqV2G/e3KNEoGIyH4kdrDYw40Qur0ZgrvPcfdZ7j6rvn6/V0h3qaG6hHVbdu1/RhGRFMt3IlhnZmMB4vP6XBbWUFXKph0t7G7t7uZUIiKS70RwO3BJHL4EuC2XhTVUh7vird+yO5fFiIgc0HJ5+uhNwN+AQ81spZldBlwFnGVmSwg3db8qV+UD1FeXALB+q5qHRES6k7PeR939Xd1MOiNXZXbWUKUagYjI/gzrK4sbYo1AB4xFRLo3rBNBXXkxRQXGuq2qEYiIdGdYJ4JMxhhdVaoagYhID4Z1IgCoryrRMQIRkR4M+0TQUF2is4ZERHqQgkRQyjrVCEREupWKRLB5Zwu7WnR1sYhIV4Z9IhhdFS8qU61ARKRLwz8RxG4m1uk4gYhIl4Z9Iui4qEw1AhGRrg3/RBC7mdC1BCIiXRv2iaC2vIjigoyahkREujHsE4GZMbpaF5WJiHRn2CcCCGcOqWlIRKRrqUgE4aIyJQIRka6kJhGs3byLcJtkERHJlopEMK62lO172ti6uzXpUEREhpxUJIKxNWUArGlW85CISGepSATjasO1BKs370w4EhGRoScViUA1AhGR7qUiEYyuKiFjsEY1AhGRV0lFIigsyDC6qpTVqhGIiLxKKhIBwNjaUtUIRES6kJpEMK6mjLWbVSMQEeksNYlgbE0pqzfv1EVlIiKdpCcR1Jaxq6Wd5h0tSYciIjKkpCYRjKvRtQQiIl1JTSIYW6trCUREupKeRBBrBDpzSERkX6lJBKMqSyjMGGt05pCIyD5SkwgKMkZDdakSgYhIJ4kkAjP7lJk9bWZPmdlNZlaaj3LH1ZayullNQyIi2fKeCMxsPPAJYJa7TwcKgIvyUfbYmjLVCEREOkmqaagQKDOzQqAcWJ2PQsfWhjuVtbfrojIRkQ55TwTuvgr4JvASsAbY7O6/7zyfmV1uZvPNbH5TU9OglD2hrpw9be00bds9KMsTERkOkmgaqgMuBKYA44AKM3tv5/ncfY67z3L3WfX19YNS9oS6cC3Byk07BmV5IiLDQRJNQ2cCL7h7k7u3ALcAr8tHwRPrygFYsVEHjEVEOiSRCF4CjjezcjMz4AxgUT4KVo1AROTVkjhGMA+4GXgUeDLGMCcfZZcWFTCqsoSVm1QjEBHpUJhEoe7+ZeDLSZQ9oa5MiUBEJEtqrizuMHFEuZqGRESypC4RTKgrY1XzTtp0LYGICJDSRNDS5qzfqiuMRUQglYkgnEKq4wQiIkHqEsFEnUIqIrKP1CWCcfFOZbqoTEQkSF0iKC0qYHRViWoEIiJR6hIB6FoCEZFsqUwE4VoCJQIREUhpIphQV8ZqXUsgIgKkNBFMrCuntd1120oREVKaCCaPrABg+cs6YCwikspE0DgqXFT24svbE45ERCR5qUwEDVWllBRmWK5EICKSzkSQyRiTR5bzopqGRETSmQggHCdQjUBEJMWJoHFkOctf3kG7TiEVkZRLbSKYPLKC3a3trFN31CKScqlNBI3xFNIXN+g4gYikW2oTweSR4RRSHScQkbRLbSIYV1tGUYHpzCERSb3UJoKCjDFxRLlqBCKSeqlNBBCOE6hGICJpl+pEMHlkqBG46xRSEUmvVCeCxpEV7NjTRtPW3UmHIiKSmFQngqn14RTS5zfoOIGIpFeqE8G0+koAljVtSzgSEZHkpDoRjKkupby4gGXrVSMQkfRKdSLIZIyp9RWqEYhIqqU6EUBoHlIiEJE0K9zfDGZWClwGHAmUdox39/f3t1AzqwV+BEwHHHi/u/+tv8sbiGn1ldz+xGp27mmjrLggiRBERBLVmxrBT4ExwDnAA8AEYOsAy/02cLe7HwbMABYNcHn9Nq2+End4foNqBSKSTr1JBAe5+5eA7e5+PfBG4Lj+FmhmNcDJwLUA7r7H3Zv7u7yBmjY6nEK6rEkHjEUknXqTCFric7OZTQdqgNEDKHMK0AT82MweM7MfmVlF55nM7HIzm29m85uamgZQXM8aR1aQMVi2XjUCEUmn3iSCOWZWB/wzcDvwDPC1AZRZCBwNfN/dZwLbgSs7z+Tuc9x9lrvPqq+vH0BxPSstKmDiiHIdMBaR1OpNIrjP3Te5+5/cfaq7jwZ+P4AyVwIr3X1efH0zITEkZlp9JUtVIxCRlOpNIvhNF+Nu7m+B7r4WWGFmh8ZRZxBqGYmZVl/BCxu206b7F4tICnV7+qiZHUY4ZbTGzN6aNamarNNI++njwI1mVgw8D7xvgMsbkGn1lexubWd1804mjihPMhQRkbzr6TqCQ4HzgVrgTVnjtwIfHEih7v44MGsgyxhMB40OfQ49t26rEoGIpE63icDdbwNuM7MTkrrYK18OGVMFwLNrt3LG4Q0JRyMikl89NQ19h3DVL2b2rs7T3f0TOYwrr6pLixhXU8pz6wZ6nZyIyIGnp6ah+XmLYgg4dEwVi9cqEYhI+vTUNHR99mszK3f3YXuD30PHVPPnpRtoaWunqCD1ffGJSIrs9xfPzE4ws2eAZ+PrGWb2vzmPLM8OG1NFS5vzvLqaEJGU6c2u79WEDudeBnD3Jwh9BQ0rh+49YLwl4UhERPKrV20g7r6i06i2HMSSqGn1lRRmTMcJRCR19ns/AsJVwK8D3MyKgCtIsNvoXCkuzDC1vkKJQERSpzc1gg8BHwXGA6uAo+LrYefQMdU8q0QgIimz3xqBu28A3pOHWBJ32Jgq7nhiNVt3tVBVWpR0OCIiedFjjcDMTjOzW8zs6fi42cxOzVNseXdIQzhgrAvLRCRNuk0EZvZG4DrgDuDdhFrBXcB1ZnZefsLLr8PHhkTwzBolAhFJj56ahj4LvDmeLtrhcTObD3yHkBSGlfG1ZdSWF/H0qs1JhyIikjc9NQ2N6ZQEAHD3hcCw7JnNzJg+roanVisRiEh69JQIerrEdthefjt9fA2L125lT2t70qGIiORFT01D08zs9i7GGzA1R/Ekbvr4alranOfWbWX6+JqkwxERybmeEsGFPUz75mAHMlRMHxd+/J9evVmJQERSoafeRx/IZyBDxaQR5VSVFPLkqs28c3bS0YiI5J76W+4kkzGOGFfNU6vU+ZyIpIMSQRemj69h0ZottLbpgLGIDH+9uR9BaRfjRuUmnKFh+vhqdre2s0z3JhCRFOhNjeARMzu+44WZvQ34a+5CSl7HAeMndWGZiKRAb7qhfjehW4m5wDhgJHB6LoNK2tT6SipLCnliRTNvP2ZC0uGIiORUb3offdLMvgr8FNgKnOzuK3MeWYIKMsaMiTU8tmJT0qGIiORcb44RXAt8Engt8D7gTjMblvcjyDZzYh2L1mxl555hdzM2EZF99OYYwZPAae7+grvfAxwHHJ3bsJI3c1Itbe3OwpXNSYciIpJT+00E7n61u3vW683uflluw0reURNrAXhshRKBiAxv+z1GYGYHA/8FHAHsPZXU3Ydtf0MAIytLaBxZzmMv6TiBiAxvvWka+jHwfaAVOA24AfhZLoMaKmZOquPRl5rJqhCJiAw7vUkEZe5+H2Duvtzd/xV4Y27DGhpmTqqlaetuVm/elXQoIiI505vrCHabWQZYYmYfA1YBlbkNa2iYObEOgMde2sT42rKEoxERyY3e1AiuAMqBTwDHAH8PXDLQgs2swMweM7M7B7qsXDlsbBWlRRnmv6jjBCIyfPXmgrJH4uA2wnUEg+UKYBFQPYjLHFRFBRmOnlTHwy9sTDoUEZGc6TYRdHN3sr3c/YL+FmpmEwjHGb4KfLq/y8mH46aM5Or7nmPzjhZqyouSDkdEZND1VCM4AVgB3ATMI9yicrBcDXwOqOpuBjO7HLgcYNKkSYNYdN8cO2UE7jB/+UbOOLwhsThERHKlp2MEY4AvANOBbwNnARvc/YGB3L3MzM4H1rv7gp7mc/c57j7L3WfV19f3t7gBmzmpluKCDPPUPCQiw1S3icDd29z9bne/BDgeWArMjWcODcSJwAVm9iLwC+B0Mxuy1yWUFhUwY2KNEoGIDFs9njVkZiVm9lbCBWQfBa4BfjuQAt398+4+wd0bgYuA+939vQNZZq4dN2UkT63azLbdrUmHIiIy6LpNBGZ2A/A3Qgdz/+bus9393919Vd6iGyKOnTKCtnbn0eU6jVREhp+eagTvBQ4mnOb5VzPbEh9bzWxQ7uzu7nPd/fzBWFYuHTO5joKM8dDzLycdiojIoOv2rCF3143to4qSQo6aWMtflikRiMjwox/7Xjrp4FEsXNlM8449SYciIjKolAh66aSD63GHvyxVrUBEhhclgl6aMaGGqtJCHlzSlHQoIiKDSomglwoLMpw4bRQPLtmg+xOIyLCiRNAHJx0yilXNO3l+w/akQxERGTRKBH1w0kGhq4sHn1PzkIgMH0oEfTBpZDmTR5bzgBKBiAwjSgR9dMZhDfxl2cvs2KPuJkRkeFAi6KMzjxjNntZ2HlyyIelQREQGhRJBH81uHEF1aSH3PrMu6VBERAaFEkEfFRVkOO2w0dz/7Hra2nUaqYgc+JQI+uHMwxvYuH0Pj72k3khF5MCnRNAPpxxaT2HGuHeRmodE5MCnRNAP1aVFnDBtJPc8tVZXGYvIAU+JoJ/Oe81YXnx5B0+vHpRbM4iIJEaJoJ/OPXIMhRnjjoWrkw5FRGRAlAj6qa6imNcfPIrfLVyj5iEROaApEQzA+a8dx8pNO3l8RXPSoYiI9JsSwQCcfWQDxQUZ7ly4JulQRET6TYlgAKpLizjl0HrueGI1rW3tSYcjItIvSgQD9Lajx7N+6271PSQiBywlggE6/bAGRlQU8+sFK5IORUSkX5QIBqi4MMObjxrPvc+sY+P2PUmHIyLSZ0oEg+AdsybQ0ubc9viqpEMREekzJYJBcPjYaqaPr+ZX81fqmgIROeAoEQySi2ZPYtGaLTyqHklF5ACjRDBI3jJzPFWlhVz/1+VJhyIi0idKBIOkoqSQdxwzkbueXMP6LbuSDkdEpNeUCAbRxSdMps2dG+e9lHQoIiK9lvdEYGYTzeyPZvaMmT1tZlfkO4ZcaRxVwamH1HPjvJfY3dqWdDgiIr2SRI2gFfhHdz8COB74qJkdkUAcOXHZ66eyYdtubnlUp5KKyIEh74nA3de4+6NxeCuwCBif7zhy5cSDRjJjQg0/eGCZ+h8SkQNCoscIzKwRmAnM62La5WY238zmNzU15Tu0fjMzPnLaQSx/eQe/e1K9korI0JdYIjCzSuA3wCfd/VX3e3T3Oe4+y91n1dfX5z/AATjr8AYOHl3J//5xGe3tusBMRIa2RBKBmRURksCN7n5LEjHkUiZjfPjUaSxet5XfP7M26XBERHqUxFlDBlwLLHL3/8l3+flywYxxTKuv4Bv3LNaxAhEZ0pKoEZwI/D1wupk9Hh/nJRBHThUWZPjsOYexrGk7Ny9YmXQ4IiLdKsx3ge7+Z8DyXW4SzjmygZmTarn6D0u48KjxlBUXJB2SiMir6MriHDIzrjz3MNZu2cV1f3kh6XBERLqkRJBjx00dyTlHNvDd+5eyqnln0uGIiLyKEkEefOn8I3Ccf7/jmaRDERF5FSWCPJhQV87HTz+Yu59eyx8Xr086HBGRfSgR5MkHT5rK1PoKvnTrU2zb3Zp0OCIieykR5ElxYYavve21rGreyVd/tyjpcERE9lIiyKPZjSO4/KSp3PTwS2oiEpEhQ4kgzz511iEc0lDJP928kJe37U46HBERJYJ8Ky0q4FvvPIrmnS188peP06ZO6UQkYUoECThyXA1fueBIHlyygW//4bmkwxGRlFMiSMg7Z0/kHcdM4Jr7l3LvM+uSDkdEUkyJICFmxr+/eTqvnVDDJ256jCdWNCcdkoiklBJBgkqLCrj2ktmMqirmsusfYcXGHUmHJCIppESQsPqqEn7yvmNpbXcuvu5h1m3ZlXRIIpIySgRDwLT6Sq69ZDbrt+ziXXMeUjIQkbxSIhgijplcxw2XHcu6mAzWbFZPpSKSH0oEQ8gxk0dw/fuPZf3W3bzle3/l2bVbkg5JRFJAiWCImdU4gl/9wwk4zju+/zf+vGRD0iGJyDCnRDAEHTGumt9+5ETG1pZy8XXz+P7cZbTrCmQRyRElgiFqXG0Zt3zkRN7wmrF87e5nufynC2jesSfpsERkGFIiGMIqSwr57rtm8uU3HcHcxes5+1t/0lXIIjLolAiGODPjfSdO4daPnsiIimI+eMN8PvmLx9ignktFZJAoERwgpo+v4faPvZ4rzjiYOxeu4bRvzGXOn5axu7Ut6dBE5ACnRHAAKS7M8KmzDuHuT57M7Ckj+M+7nuXsb/2JX89fQUtbe9LhicgBSongAHTQ6Equu3Q217//WCqKC/nszQs5/b/n8vN5L7GrRTUEEekbcx/6pyXOmjXL58+fn3QYQ5K7c9+i9Xzn/iU8sXIzNWVFvOOYCbzn+MlMGVWRdHgikiAzW+Dus/Y7nxLB8ODuPPT8Rn42bzn3PLWW1nZndmMdb5oxjvNeM5ZRlSVJhygieaZEkGLrt+zi1wtWctvjq3hu3TYKMsYJU0dy6qH1nHroaKbVV2BmSYcpIjmmRCAALF67ldufWMU9T69j6fptAEyoK+Okg0dxzOQRHDO5jsaR5UoMIsOQEoG8yoqNO3jguSbmLm7i4RdeZsuuVgBGVRYzc1IdR4yt5vCxVRw2pppJI8rJZJQcRA5kSgTSo/Z2Z2nTNua/uIkFyzfx2IpNvLhhOx1dGpUXF3DQ6Eomj6xg8ohyJo0sp3FkBZNHllNfWaIkIXIAGNKJwMzOBb4NFAA/cvereppfiSA/du5p47l1W3l27RYWrdnK0vXbWL5xO6ubd9GW1eldQcaoryyhobqE0dWlNFSX0FBVyojKYmrLiqktL6KmrIja8iJqy4upKC5Q05NIAnqbCArzEUw2MysAvgecBawEHjGz2939mXzHIvsqKy5gxsRaZkys3Wd8S1s7qzbtZPnGHby0cQfrNu9i3ZZdrNu6mxUbd7Bg+SY2bu++Q7zCjFFdVkRFSQEVxYWUFWc/F1BWXEhFcQHlxQWUFBVQXJChuDBD0d5no2Sf1+G5uCBDYYFRYEYmE54LMq8MZzJQYEZhJhOGM0YmztPxHhFJIBEAxwJL3f15ADP7BXAhoEQwRBUVZGgcVUFjD9cl7G5to3lHS3zsoXlnC5t3tNC8c08Yt7OFnXva2L67lZ0t4XnDtt3s2NMWH63s2JP/i+E6kgLhH2HQ4jN7azIW/+sYlz29433E93XM3+2ybN9p/dHfFNbfmlm/U2Y/3njonudnAAAI00lEQVTAfLY8ufaS2UwaWZ7TMpJIBOOBFVmvVwLHdZ7JzC4HLgeYNGlSfiKTfispLKChuoCG6tJ+L6O93Wlpb2dPazstbR6f29kdn/dkPe+Jz63tTlu70+7h+ZVhaHOnvf2V8W1xnvY43L53HDhO/Ie743EYiMNhHB3TO43veB3nCOO6mN65nP7ob2Nuf1uB+19e39/Z74bqfn+2oX+MtLgw9x1AJJEIesXd5wBzIBwjSDgcyYNMxijJFFBSWJB0KCKpkkRfQ6uAiVmvJ8RxIiKSgCQSwSPAwWY2xcyKgYuA2xOIQ0RESKBpyN1bzexjwD2E00evc/en8x2HiIgEiRwjcPe7gLuSKFtERPal+xGIiKScEoGISMopEYiIpJwSgYhIyh0QvY+aWROwvJ9vHwVsGMRwBovi6hvF1TeKq2+Ga1yT3b1+fzMdEIlgIMxsfm9638s3xdU3iqtvFFffpD0uNQ2JiKScEoGISMqlIRHMSTqAbiiuvlFcfaO4+ibVcQ37YwQiItKzNNQIRESkB0oEIiIpN6wTgZmda2aLzWypmV2Zx3InmtkfzewZM3vazK6I40eY2b1mtiQ+18XxZmbXxDgXmtnROY6vwMweM7M74+spZjYvlv/L2D04ZlYSXy+N0xtzGFOtmd1sZs+a2SIzO2EorC8z+1T8Gz5lZjeZWWkS68vMrjOz9Wb2VNa4Pq8fM7skzr/EzC7JUVzfiH/HhWb2WzOrzZr2+RjXYjM7J2v8oH5Xu4ora9o/mpmb2aj4OtH1Fcd/PK6zp83s61nj87K+4m35ht+D0MX1MmAqUAw8ARyRp7LHAkfH4SrgOeAI4OvAlXH8lcDX4vB5wP8j3D71eGBejuP7NPBz4M74+lfARXH4B8CH4/BHgB/E4YuAX+YwpuuBD8ThYqA26fVFuK3qC0BZ1nq6NIn1BZwMHA08lTWuT+sHGAE8H5/r4nBdDuI6GyiMw1/LiuuI+D0sAabE72dBLr6rXcUVx08kdIG/HBg1RNbXacAfgJL4enTe11cuvkBD4QGcANyT9frzwOcTiuU24CxgMTA2jhsLLI7DPwTelTX/3vlyEMsE4D7gdODOuPFvyPri7l1v8QtzQhwujPNZDmKqIfzgWqfxia4vXrm/9oj4+e8EzklqfQGNnX5A+rR+gHcBP8wav898gxVXp2lvAW6Mw/t8BzvWV66+q13FBdwMzABe5JVEkOj6IuxYnNnFfHlbX8O5aajjS9xhZRyXV7F5YCYwD2hw9zVx0lqgIQ7nM9argc8B7fH1SKDZ3Vu7KHtvXHH65jj/YJsCNAE/jk1WPzKzChJeX+6+Cvgm8BKwhvD5F5D8+urQ1/WTxHfi/YS97cTjMrMLgVXu/kSnSUmvr0OAk2Jz4gNmNjvfcQ3nRJA4M6sEfgN80t23ZE/zkMrzeu6umZ0PrHf3BfkstxcKCdXl77v7TGA7oaljr4TWVx1wISFRjQMqgHPzGUNvJbF+9sfMvgi0AjcOgVjKgS8A/5J0LF0oJNQ6jwc+C/zKzCyfAQznRLCK0B7YYUIclxdmVkRIAje6+y1x9DozGxunjwXW5znWE4ELzOxF4BeE5qFvA7Vm1nG3uuyy98YVp9cAL+cgrpXASnefF1/fTEgMSa+vM4EX3L3J3VuAWwjrMOn11aGv6ydv3wkzuxQ4H3hPTFJJxzWNkNCfiNv/BOBRMxuTcFwQtv9bPHiYUFsflc+4hnMieAQ4OJ7hUUw4eHd7PgqO2fxaYJG7/0/WpNuBjjMPLiEcO+gYf3E8e+F4YHNWlX/QuPvn3X2CuzcS1sf97v4e4I/A27uJqyPet8f5B32v093XAivM7NA46gzgGRJeX4QmoePNrDz+TTviSnR9Zenr+rkHONvM6mJt5+w4blCZ2bmE5scL3H1Hp3gvsnB21RTgYOBh8vBddfcn3X20uzfG7X8l4YSOtSS8voBbCQeMMbNDCAeAN5DP9TXQAx9D+UE4G+A5whH2L+ax3NcTqukLgcfj4zxCe/F9wBLCWQIj4vwGfC/G+SQwKw8xnsorZw1NjRvYUuDXvHL2Qml8vTROn5rDeI4C5sd1divhLI3E1xfwb8CzwFPATwlncOR9fQE3EY5TtBB+xC7rz/ohtNkvjY/35SiupYQ27I5t/wdZ838xxrUYeEPW+EH9rnYVV6fpL/LKweKk11cx8LO4jT0KnJ7v9aUuJkREUm44Nw2JiEgvKBGIiKScEoGISMopEYiIpJwSgYhIyikRyLBnZtvic6OZvXuQl/2FTq//OpjLF8kHJQJJk0agT4kg6wri7uyTCNz9dX2MSSRxSgSSJlcROvd63MJ9Bgos9J3/SOyH/h8AzOxUM3vQzG4nXEmMmd1qZgtif/GXx3FXAWVxeTfGcR21D4vLfsrMnjSzd2Yte669cu+FGzv6lTGzqyzcw2KhmX0z72tHUmt/ezsiw8mVwGfc/XyA+IO+2d1nm1kJ8Bcz+32c92hguru/EF+/3903mlkZ8IiZ/cbdrzSzj7n7UV2U9VbC1dIzCP3GPGJmf4rTZgJHAquBvwAnmtkiQpfNh7m7W9bNXERyTTUCSbOzCX3MPE7oJnwkoT8XgIezkgDAJ8zsCeAhQodfB9Oz1wM3uXubu68DHgA6uhd+2N1Xuns7oQuGRkKX1buAa83srcCOLpYpkhNKBJJmBnzc3Y+Kjynu3lEj2L53JrNTCT2RnuDuM4DHCP0K9dfurOE2wk1uWoFjCT2vng/cPYDli/SJEoGkyVbCrUM73AN8OHYZjpkdYuGGOJ3VAJvcfYeZHUboN75DS8f7O3kQeGc8DlFPuEXhw90FZuHeFTXufhfwKUKTkkhe6BiBpMlCoC028fyEcC+GRkK/9Ea4S9qbu3jf3cCHYjv+YkLzUIc5wEIze9RDl94dfku4peAThJ5oP+fua2Mi6UoVcJuZlRJqKp/u30cU6Tv1PioiknJqGhIRSTklAhGRlFMiEBFJOSUCEZGUUyIQEUk5JQIRkZRTIhARSbn/Dy75046RLNrMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot iteration vs delta\n",
    "plt.plot(range(iterations), delta_list)\n",
    "plt.title('Value Iteration with Discount Factor ' + str(discount_factor))\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Max Delta')\n",
    "plt.savefig('graphs/Value-'+str(discount_factor)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Policy Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas library\n",
    "import pandas as pd\n",
    "# define column and index\n",
    "columns=range(grid.size)\n",
    "index = range(grid.size)\n",
    "# define dataframe to represent policy table\n",
    "policy_table = pd.DataFrame(index = index, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through policy to make a table that represents action number\n",
    "# as action name (eg. left, right, up, down)\n",
    "for state in range(len(policy)):\n",
    "    for action in range(policy.shape[1]):\n",
    "        if policy[state][action] == 1:\n",
    "            \n",
    "            # calculate the row and column coordinate of the current state number\n",
    "            row = int(state/grid.size)\n",
    "            column = round((state/grid.size - int(state/grid.size))*grid.size)\n",
    "\n",
    "            # get action name\n",
    "            if action == 0:\n",
    "                action_name = 'up'\n",
    "            elif action == 1:\n",
    "                action_name = 'right'\n",
    "            elif action == 2:\n",
    "                action_name = 'down'\n",
    "            else:\n",
    "                action_name = 'left'\n",
    "            \n",
    "            # assign action name\n",
    "            policy_table.loc[row][column] = action_name\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>right</td>\n",
       "      <td>up</td>\n",
       "      <td>left</td>\n",
       "      <td>up</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>left</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1     2     3     4\n",
       "0  right  up  left    up  left\n",
       "1     up  up    up  left  left\n",
       "2     up  up    up    up    up\n",
       "3     up  up    up    up    up\n",
       "4     up  up    up    up    up"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print policy table\n",
    "policy_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
