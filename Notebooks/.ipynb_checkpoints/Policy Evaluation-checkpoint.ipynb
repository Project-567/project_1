{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the value function of policy\n",
    "import numpy as np\n",
    "\n",
    "# display output\n",
    "from random import uniform\n",
    "import time\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [[-1, 0], [0, 1], [1, 0], [0, -1]] #up, right, down, left = (clockwise from up) \n",
    "action_count = len(actions) # total number of actions\n",
    "gridSize = 5 # create a square grid of gridSize by gridSize\n",
    "state_count = gridSize*gridSize # total number of states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridworld Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gridworld():\n",
    "    def __init__(self, gridSize):\n",
    "        self.valueMap = np.zeros((gridSize, gridSize))\n",
    "        self.states = [[i, j] for i in range(gridSize) for j in range(gridSize)]\n",
    "        self.size = gridSize\n",
    "        self.new_pos = [0, 0] # initialize new position for p_transition\n",
    "        self.pos_check = [0, 0] # a copy of new position\n",
    "        self.transition_prob = 1 # deterministic\n",
    "    \n",
    "    def initial_state(self):\n",
    "        # randomly generate an initial state\n",
    "        i = random.randint(0, len(self.states)-1)\n",
    "        rand_state = self.states[i]\n",
    "        return rand_state\n",
    "    \n",
    "    def possible_states(self):\n",
    "        # return the possible states\n",
    "        return self.states\n",
    "    \n",
    "    def reward(self, current_pos, action):\n",
    "        # return the reward        \n",
    "        \n",
    "        # take action in current pos\n",
    "        self.new_pos = np.array(current_pos) + np.array(action)\n",
    "\n",
    "        # normally, reward = 0\n",
    "        reward = 0\n",
    "\n",
    "        # if new pos results in off the grid, return reward -1\n",
    "        if -1 in self.new_pos or self.size in self.new_pos:\n",
    "            reward = -1\n",
    "        # if in state A, transition to state A'\n",
    "        if current_pos == [0, 1]:\n",
    "            reward = 10\n",
    "        # if in state B, transition to state B'\n",
    "        if current_pos == [0, 3]:\n",
    "            reward = 5\n",
    "        return reward\n",
    "    \n",
    "    # def transition_probability(self, current_pos, new_pos):\n",
    "        # a function that returns the entries of the transition probability matrix?\n",
    "        # eg. input current state, new state, output = 0.25...0.5...1 ... etc. ?\n",
    "    \n",
    "    def p_transition(self, current_pos, action):\n",
    "        # return the transition probability\n",
    "        # get next position: state: [0, 0], action: [0, 1], new_state = [0, 1]\n",
    "        self.new_pos = np.array(current_pos) + np.array(action)\n",
    "        self.pos_check = self.new_pos # make a copy of new pos before being overwritten below\n",
    "\n",
    "        # if taking an action crosses the border = agent stays in same position\n",
    "        if -1 in self.new_pos or self.size in self.new_pos: \n",
    "            self.new_pos = current_pos\n",
    "            \n",
    "        # if in state A, transition to state A'\n",
    "        if current_pos == [0, 1]:\n",
    "            self.new_pos = [4, 1]\n",
    "            \n",
    "        # if in state B, transition to state B'\n",
    "        if current_pos == [0, 3]:\n",
    "            self.new_pos = [2, 3]\n",
    "        return self.new_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Evaluation Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(value_map, states, discount_factor, theta, reward, transition, trans_prob, policy):\n",
    "    iterations = 0\n",
    "    delta_list = []\n",
    "    while True:\n",
    "        delta = 0\n",
    "        iterations+=1\n",
    "        valueMap_copy = np.copy(value_map)\n",
    "\n",
    "        # start with the first state in the state list\n",
    "        for state_number, state in enumerate(states):\n",
    "            value = 0\n",
    "\n",
    "            # perform 4 actions per state and add the rewards (value)\n",
    "            for action_number, action in enumerate(actions):\n",
    "\n",
    "                # get next position and reward\n",
    "                new_position = transition(state, action)\n",
    "                rewards = reward(state, action)\n",
    "\n",
    "                # calculate value: policy*transition_prob*[r + gamma * value(s')]\n",
    "                value += policy[state_number][action_number]*trans_prob*(rewards+(discount_factor*value_map[new_position[0], new_position[1]]))          \n",
    "\n",
    "            # replace the value in valueMap with the value\n",
    "            valueMap_copy[state[0], state[1]] = value\n",
    "\n",
    "            # calculate delta\n",
    "            delta = max(delta, np.abs(value - value_map[state[0], state[1]]))      \n",
    "            clear_output(wait=True)\n",
    "            display('delta: ' + str(delta) + ' iterations: ' + str(iterations))\n",
    "\n",
    "        # save data for plot\n",
    "        delta_list.append(delta)\n",
    "\n",
    "        # overwrite the original value map (update valuemap after one complete iteration of every state)\n",
    "        value_map = valueMap_copy\n",
    "\n",
    "        # stop when change in value function falls below a given threshold\n",
    "        if delta < theta:\n",
    "            break\n",
    "    \n",
    "    return value_map, iterations, delta_list, policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Policy Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'delta: 9.987400479971598e-07 iterations: 929'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define variables\n",
    "theta = 0.000001\n",
    "discount_factor = 0.99\n",
    "\n",
    "# create a grid object\n",
    "grid = Gridworld(5)\n",
    "\n",
    "# initialize a policy: create an array of dimension (number of states by number of actions)\n",
    "# for equal probability amongst all actions, divide everything by the number of actions\n",
    "policy = np.ones([state_count, action_count]) / action_count\n",
    "\n",
    "# run policy evaluation\n",
    "final_value_map, max_iter, delta, policy = policy_evaluation(grid.valueMap, grid.states, discount_factor, theta, grid.reward, \n",
    "                                                                grid.p_transition, grid.transition_prob, policy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Iterations and Value Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Iterations: \n",
      "929\n",
      "Value Function: \n",
      "[[ 3.2175  7.1243  4.3031  4.7526  1.5245]\n",
      " [ 1.4609  2.7247  2.2163  1.7565  0.3782]\n",
      " [-0.4904  0.2073  0.1705 -0.2499 -1.1211]\n",
      " [-2.1493 -1.5671 -1.4849 -1.8157 -2.5267]\n",
      " [-3.467  -2.9047 -2.7873 -3.0748 -3.7354]]\n"
     ]
    }
   ],
   "source": [
    "# print the final value function\n",
    "print(\"Total Iterations: \")\n",
    "print(max_iter)\n",
    "print(\"Value Function: \")\n",
    "np.set_printoptions(precision=4)\n",
    "print(final_value_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Convergence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print delta vs iterations\n",
    "import matplotlib.pyplot as plt\n",
    "# plot iteration vs delta\n",
    "plt.plot(range(max_iter), delta)\n",
    "plt.title('Policy Evaluation with Discount Factor ' + str(discount_factor))\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Max Delta')\n",
    "plt.savefig('graphs/Policy_Evaluation-'+str(discount_factor)+'.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
