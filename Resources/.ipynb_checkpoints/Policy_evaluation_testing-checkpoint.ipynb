{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_factor = 1\n",
    "actions = [[-1, 0], [1, 0], [0, 1], [0, -1]] #row +/- 1 or column +/- 1\n",
    "max_iters = 100\n",
    "gridSize = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate an array of zeros to represent the map\n",
    "valueMap = np.zeros((gridSize, gridSize))\n",
    "# create a list of tuples = [row, column]\n",
    "states = [[i, j] for i in range(gridSize) for j in range(gridSize)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valueMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0],\n",
       " [0, 1],\n",
       " [0, 2],\n",
       " [0, 3],\n",
       " [0, 4],\n",
       " [1, 0],\n",
       " [1, 1],\n",
       " [1, 2],\n",
       " [1, 3],\n",
       " [1, 4],\n",
       " [2, 0],\n",
       " [2, 1],\n",
       " [2, 2],\n",
       " [2, 3],\n",
       " [2, 4],\n",
       " [3, 0],\n",
       " [3, 1],\n",
       " [3, 2],\n",
       " [3, 3],\n",
       " [3, 4],\n",
       " [4, 0],\n",
       " [4, 1],\n",
       " [4, 2],\n",
       " [4, 3],\n",
       " [4, 4]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition(current_pos, action):\n",
    "    \n",
    "    # get next position: state: [0, 0], action: [0, 1], new_state = [0, 1]\n",
    "    new_pos = np.array(current_pos) + np.array(action)\n",
    "    reward = 0\n",
    "    \n",
    "    # if taking an action crosses the border = agent stays in same position\n",
    "    if -1 in new_pos or gridSize in new_pos: \n",
    "        new_pos = current_pos\n",
    "        reward = -1\n",
    "    \n",
    "    # if in state A, transition to state A'\n",
    "    if current_pos == [0, 1]:\n",
    "        new_pos = [4, 1]\n",
    "        reward = 10\n",
    "    \n",
    "    # if in state B, transition to state B'\n",
    "    if current_pos == [0, 3]:\n",
    "        new_pos = [2, 3]\n",
    "        reward = 5\n",
    "\n",
    "    return new_pos, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "[[-0.5  10.   -0.25  5.   -0.5 ]\n",
      " [-0.25  0.    0.    0.   -0.25]\n",
      " [-0.25  0.    0.    0.   -0.25]\n",
      " [-0.25  0.    0.    0.   -0.25]\n",
      " [-0.5  -0.25 -0.25 -0.25 -0.5 ]]\n",
      "\n",
      "Iteration 2\n",
      "[[ 1.6875  9.75    3.4375  5.      0.4375]\n",
      " [-0.5     2.4375 -0.0625  1.1875 -0.5   ]\n",
      " [-0.4375 -0.0625  0.     -0.0625 -0.4375]\n",
      " [-0.5    -0.125  -0.0625 -0.125  -0.5   ]\n",
      " [-0.875  -0.5    -0.4375 -0.5    -0.875 ]]\n",
      "\n",
      "Iteration 3\n",
      "[[ 2.65625   9.5       4.28125   4.9375    0.84375 ]\n",
      " [ 0.546875  2.28125   1.765625  1.09375  -0.078125]\n",
      " [-0.625     0.46875  -0.0625    0.15625  -0.625   ]\n",
      " [-0.734375 -0.28125  -0.171875 -0.28125  -0.734375]\n",
      " [-1.1875   -0.734375 -0.625    -0.734375 -1.1875  ]]\n",
      "\n",
      "Iteration 10\n",
      "[[ 4.35138035  8.35102081  5.30830669  5.55983734  2.0662508 ]\n",
      " [ 2.41210365  3.73263168  3.08720779  2.48477173  0.95953941]\n",
      " [ 0.41044044  1.10420322  1.08833504  0.55556202 -0.35133934]\n",
      " [-1.15541267 -0.51126671 -0.45696068 -0.74501228 -1.49310112]\n",
      " [-2.32684231 -1.74187183 -1.56627369 -1.8443346  -2.48298168]]\n",
      "\n",
      "Iteration 100\n",
      "[[ 3.32619594  7.01709435  4.4171919   4.83249172  1.70289392]\n",
      " [ 1.59041014  2.82147893  2.35710977  1.89604338  0.5284238 ]\n",
      " [-0.42133169  0.27641699  0.24884498 -0.17872703 -1.0585384 ]\n",
      " [-2.17570929 -1.58820863 -1.5042997  -1.8461335  -2.57018467]\n",
      " [-3.56247458 -2.99412683 -2.87658158 -3.17619815 -3.85075495]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# policy evaluation\n",
    "for it in range(max_iters):\n",
    "    valueMap_copy = np.copy(valueMap)\n",
    "    # start with the first state in the state list\n",
    "    for state in states:\n",
    "        weightedRewards = 0\n",
    "        # perform 4 actions per state and add the rewards (weightedRewards)\n",
    "        for action in actions:\n",
    "            # get next position and reward\n",
    "            new_position, reward = transition(state, action)\n",
    "            # calculate weighted rewards: 1/4[r + gamma * value(s')]\n",
    "            weightedRewards += (1/len(actions))*(reward+(discount_factor*valueMap[new_position[0], new_position[1]]))\n",
    "        # replace the value in valueMap with the weighted rewards\n",
    "        valueMap_copy[state[0], state[1]] = weightedRewards\n",
    "    # overwrite the original value map\n",
    "    valueMap = valueMap_copy\n",
    "    \n",
    "    if it in [0,1,2,9, 99, 999, max_iters-1]:\n",
    "        print(\"Iteration {}\".format(it+1))\n",
    "        print(valueMap)\n",
    "        print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
