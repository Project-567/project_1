# README

## Branch Information
- Master: Current code that is complete and functional.
- aaron: Development branch (may contain broken code)

## TO DO LIST
### As of Feb 10th 2020
- 

## Important Information
- Due: Feb. 11, 11:59pm
- ZIP Folder
    - PDF Report
    - Python Code

## Google Doc
https://docs.google.com/document/d/12n1HmnPfUfaclALzc7-_7KPOs3C_5ePQttm47y92aDQ/edit?usp=sharing

## Questions
- Question 1
    - a) Why is this problem an MDP?
        - are we suppose to describe the problem wrt "Sufficient statistic"? = P[St+1 | St] = P[St+1 | S1, S2 ... St]
    - b) what does it mean by "are these the only possible choices?"
        - there are other ways to define "states" (instead of coordinates - can be 0 - 25)
    - e) How to group bellman equations? By what criteria?
        - What we proposed so far is okay
- Question 2
    - function to return a view of all possible states
        - return a list of all possible states
    - what is the probability of a transition?

## Useful Links
- https://towardsdatascience.com/reinforcement-learning-rl-101-with-python-e1aa0d37d43b
- https://towardsdatascience.com/reinforcement-learning-implement-grid-world-from-scratch-c5963765ebff
- Python: Policy Iteraiton: https://github.com/dennybritz/reinforcement-learning/blob/master/DP/Policy%20Iteration%20Solution.ipynb